{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Simple Agentic RAG from Scratch\n",
    "\n",
    "In this notebook, we'll build a simple agentic RAG system from scratch using:\n",
    "- **Ollama** for local LLM inference\n",
    "- **Tool calling** to give the agent capabilities\n",
    "- **ReAct loop** for reasoning and acting until task completion\n",
    "\n",
    "## What is ReAct?\n",
    "\n",
    "ReAct (Reasoning + Acting) is a pattern where:\n",
    "1. Agent **thinks** about what to do next\n",
    "2. Agent **acts** by calling a tool\n",
    "3. Agent **observes** the result\n",
    "4. Repeat until task is complete\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "User Query → Agent (LLM) → Tool Call → Tool Execution → Back to Agent → Final Answer\n",
    "              ↑                                            |\n",
    "              |______________ ReAct Loop _________________|\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ollama pypdf2 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-section",
   "metadata": {},
   "source": [
    "## Step 1: Build the Tools\n",
    "\n",
    "We'll create simple tools for working with PDFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tool-find-pdfs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pdf_files(directory=\"./assets-resources/pdfs\"):\n",
    "    \"\"\"\n",
    "    Find all PDF files in the specified directory.\n",
    "\n",
    "    Args:\n",
    "        directory: Path to search for PDFs\n",
    "\n",
    "    Returns:\n",
    "        String with newline-separated list of PDF file paths\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf_files = glob.glob(f\"{directory}/**/*.pdf\", recursive=True)\n",
    "        if not pdf_files:\n",
    "            return f\"No PDF files found in {directory}\"\n",
    "        return \"\\n\".join(pdf_files)\n",
    "    except Exception as e:\n",
    "        return f\"Error finding PDF files: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tool-search-pdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pdf(pdf_path, search_pattern, context_lines=3):\n",
    "    \"\"\"\n",
    "    Search for a pattern in a PDF by first converting it to text, then searching.\n",
    "    \n",
    "    This function combines pdf_to_text and search_in_text into one simple tool.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        search_pattern: The text pattern to search for\n",
    "        context_lines: Number of lines of context to show around matches (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "        String with search results and context, or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Convert PDF to text\n",
    "        output_dir = \"text_files\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        base_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "        text_file_path = os.path.join(output_dir, f\"{base_name}.txt\")\n",
    "        \n",
    "        # Convert PDF to text using pdftotext\n",
    "        result = subprocess.run(\n",
    "            [\"pdftotext\", \"-layout\", pdf_path, text_file_path],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        \n",
    "        # Step 2: Search in the converted text file\n",
    "        search_result = subprocess.run(\n",
    "            [\"grep\", \"-i\", \"-C\", str(context_lines), search_pattern, text_file_path],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if search_result.returncode == 0:\n",
    "            return f\"Found matches for '{search_pattern}' in {pdf_path}:\\n\\n{search_result.stdout}\"\n",
    "        elif search_result.returncode == 1:\n",
    "            return f\"No matches found for '{search_pattern}' in {pdf_path}\"\n",
    "        else:\n",
    "            return f\"Error searching: {search_result.stderr}\"\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error converting PDF: {e.stderr}\"\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: pdftotext not found. Please install poppler-utils (brew install poppler on Mac)\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "\n",
    "def read_full_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Convert a PDF file to text using pdftotext and return the full text content.\n",
    "\n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "\n",
    "    Returns:\n",
    "        The full text content of the PDF, or an error message\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "\n",
    "    try:\n",
    "        output_dir = \"text_files\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        base_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "        text_file_path = os.path.join(output_dir, f\"{base_name}.txt\")\n",
    "\n",
    "        # Convert PDF to text using pdftotext\n",
    "        subprocess.run(\n",
    "            [\"pdftotext\", \"-layout\", pdf_path, text_file_path],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "\n",
    "        # Read and return the contents of the resulting text file\n",
    "        with open(text_file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            return f.read()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error converting PDF: {e.stderr}\"\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: pdftotext not found. Please install poppler-utils (brew install poppler on Mac)\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tool-read-pdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(file_path, num_lines=None):\n",
    "    \"\"\"\n",
    "    Read and return the content of a text file.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the text file\n",
    "        num_lines: Optional number of lines to read from the beginning\n",
    "\n",
    "    Returns:\n",
    "        The file content or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if num_lines:\n",
    "            result = subprocess.run(\n",
    "                [\"head\", \"-n\", str(num_lines), file_path],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                check=True\n",
    "            )\n",
    "            return result.stdout\n",
    "        else:\n",
    "            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                return f.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-tools",
   "metadata": {},
   "source": [
    "### Test the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-tools-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Find PDFs\n",
    "pdfs = find_pdf_files()\n",
    "print(f\"Found PDFs:\")\n",
    "print(pdfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-section",
   "metadata": {},
   "source": [
    "## Step 2: Define Tool Schemas for Ollama\n",
    "\n",
    "We need to define the tools in a format that Ollama understands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "tool-schemas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool schemas created successfully!\n",
      "Available tools: find_pdf_files, search_pdf, read_full_pdf\n"
     ]
    }
   ],
   "source": [
    "TOOLS = [\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'find_pdf_files',\n",
    "            'description': 'Finds all PDF files in the specified directory and subdirectories. Use this first to discover what PDFs are available.',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'directory': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'The directory path to search for PDF files (default: ./assets-resources/pdfs)'\n",
    "                    }\n",
    "                },\n",
    "                'required': []\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'search_pdf',\n",
    "            'description': 'Search for a keyword or phrase in a PDF file. This tool automatically converts the PDF to text and searches it. Returns matching excerpts with context.',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'pdf_path': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'Path to the PDF file to search'\n",
    "                    },\n",
    "                    'search_pattern': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'The keyword or phrase to search for'\n",
    "                    },\n",
    "                    'context_lines': {\n",
    "                        'type': 'integer',\n",
    "                        'description': 'Number of lines of context to show around matches (default: 3)'\n",
    "                    }\n",
    "                },\n",
    "                'required': ['pdf_path', 'search_pattern']\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'read_full_pdf',\n",
    "            'description': 'Read the full text content of a PDF file.',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'pdf_path': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'Path to the PDF file'\n",
    "                    }\n",
    "                },\n",
    "                'required': ['pdf_path']\n",
    "            }\n",
    "        }\n",
    "    }   \n",
    "]\n",
    "\n",
    "print(\"Tool schemas created successfully!\")\n",
    "print(f\"Available tools: {', '.join([tool['function']['name'] for tool in TOOLS])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-class",
   "metadata": {},
   "source": [
    "## Step 3: Build the Simple ReAct Agent\n",
    "\n",
    "Now we'll create a simple agent class that implements the ReAct loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "agent-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class SimpleAgent:\n",
    "    def __init__(self, model=\"mistral-small3.2\", max_turns=10, verbose=True):\n",
    "        \"\"\"\n",
    "        Initialize a simple ReAct agent.\n",
    "        \n",
    "        Args:\n",
    "            model: Ollama model to use\n",
    "            max_turns: Maximum number of reasoning-action turns\n",
    "            verbose: Whether to print agent's reasoning process\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.max_turns = max_turns\n",
    "        self.verbose = verbose\n",
    "        self.tools_map = {\n",
    "            'find_pdf_files': find_pdf_files,\n",
    "            'search_pdf': search_pdf,\n",
    "            'read_text_file': read_text_file\n",
    "        }\n",
    "        \n",
    "    def execute_tool(self, tool_name: str, arguments: Dict[str, Any]) -> str:\n",
    "        \"\"\"Execute a tool and return its result.\"\"\"\n",
    "        if tool_name not in self.tools_map:\n",
    "            return f\"Error: Tool '{tool_name}' not found\"\n",
    "        \n",
    "        try:\n",
    "            result = self.tools_map[tool_name](**arguments)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"Error executing {tool_name}: {str(e)}\"\n",
    "    \n",
    "    def run(self, user_query: str) -> str:\n",
    "        \"\"\"\n",
    "        Run the agent with a user query using the ReAct loop.\n",
    "        \n",
    "        Args:\n",
    "            user_query: The user's question or task\n",
    "        \n",
    "        Returns:\n",
    "            Final answer from the agent\n",
    "        \"\"\"\n",
    "        # Initialize conversation history\n",
    "        messages = [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': '''You are a helpful assistant that can search through PDF documents to answer questions.\n",
    "\n",
    "Use the available tools to:\n",
    "1. First, find what PDFs are available using find_pdf_files(directory=\"./assets-resources/pdfs\")\n",
    "2. Search for relevant keywords in PDFs using search_pdf(pdf_path, search_pattern, context_lines=3)\n",
    "3. Read the full text content of a PDF file using read_full_pdf(pdf_path) when you need to read the entire content of a PDF file to answer the question.\n",
    "\n",
    "Think carefully and use tools as needed. \n",
    "When you have enough information to answer the user's question, provide a clear final answer.\n",
    "'''\n",
    "            },\n",
    "            {'role': 'user', 'content': user_query}\n",
    "        ]\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"User Query: {user_query}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        # ReAct loop\n",
    "        for turn in range(self.max_turns):\n",
    "            if self.verbose:\n",
    "                print(f\"\\n--- Turn {turn + 1}/{self.max_turns} ---\")\n",
    "            \n",
    "            # Get response from LLM\n",
    "            response = ollama.chat(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                tools=TOOLS\n",
    "            )\n",
    "            \n",
    "            assistant_message = response['message']\n",
    "            \n",
    "            # Check if agent wants to call a tool\n",
    "            if 'tool_calls' in assistant_message and assistant_message['tool_calls']:\n",
    "                # Add assistant's tool call to history\n",
    "                messages.append(assistant_message)\n",
    "                \n",
    "                # Execute each tool call\n",
    "                for tool_call in assistant_message['tool_calls']:\n",
    "                    tool_name = tool_call['function']['name']\n",
    "                    arguments = tool_call['function']['arguments']\n",
    "                    \n",
    "                    if self.verbose:\n",
    "                        print(f\"\\n🔧 Tool Call: {tool_name}\")\n",
    "                        print(f\"   Arguments: {arguments}\")\n",
    "                    \n",
    "                    # Execute the tool\n",
    "                    tool_result = self.execute_tool(tool_name, arguments)\n",
    "                    \n",
    "                    if self.verbose:\n",
    "                        print(f\"   Result: {tool_result[:200]}...\" if len(tool_result) > 200 else f\"   Result: {tool_result}\")\n",
    "                    \n",
    "                    # Add tool result to messages\n",
    "                    messages.append({\n",
    "                        'role': 'tool',\n",
    "                        'content': tool_result\n",
    "                    })\n",
    "            \n",
    "            # Check if agent provided a final answer (no tool calls)\n",
    "            elif 'content' in assistant_message:\n",
    "                final_answer = assistant_message['content']\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f\"\\n✅ Final Answer (after {turn + 1} turns):\")\n",
    "                    print(f\"\\n{final_answer}\")\n",
    "                    print(f\"\\n{'='*60}\\n\")\n",
    "                \n",
    "                return final_answer\n",
    "        \n",
    "        # Max turns reached\n",
    "        return \"Max turns reached. Unable to complete the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-section",
   "metadata": {},
   "source": [
    "## Step 4: Use the Agent\n",
    "\n",
    "Let's create an agent and test it with some questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "create-agent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create the agent\n",
    "agent = SimpleAgent(\n",
    "    model=\"mistral-small3.2\",\n",
    "    max_turns=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-1",
   "metadata": {},
   "source": [
    "### Example 1: Simple Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "example-1-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User Query: What PDFs are available and what topics do they cover?\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Turn 1/10 ---\n",
      "\n",
      "🔧 Tool Call: find_pdf_files\n",
      "   Arguments: {'directory': './assets-resources/pdfs'}\n",
      "   Result: ./assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf\n",
      "./assets-resources/pdfs/lora-paper.pdf\n",
      "./assets-resources/pdfs/sparks-agi-paper.pdf\n",
      "./assets-resources/pdfs/qlora-paper.pdf\n",
      "\n",
      "--- Turn 2/10 ---\n",
      "\n",
      "🔧 Tool Call: search_pdf\n",
      "   Arguments: {'pdf_path': './assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf', 'search_pattern': 'instruction tuning'}\n",
      "   Result: No matches found for 'instruction tuning' in ./assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf\n",
      "\n",
      "--- Turn 3/10 ---\n",
      "\n",
      "🔧 Tool Call: search_pdf\n",
      "   Arguments: {'pdf_path': './assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf', 'search_pattern': 'fine-tuning'}\n",
      "   Result: No matches found for 'fine-tuning' in ./assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf\n",
      "\n",
      "--- Turn 4/10 ---\n",
      "\n",
      "🔧 Tool Call: search_pdf\n",
      "   Arguments: {'pdf_path': './assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf', 'search_pattern': 'Llama 2'}\n",
      "   Result: Found matches for 'Llama 2' in ./assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf:\n",
      "\n",
      "07/04/2024, 12:41                                                        Extended Guide: Instruction...\n",
      "\n",
      "--- Turn 5/10 ---\n",
      "\n",
      "--- Turn 6/10 ---\n",
      "\n",
      "--- Turn 7/10 ---\n",
      "\n",
      "--- Turn 8/10 ---\n",
      "\n",
      "--- Turn 9/10 ---\n",
      "\n",
      "--- Turn 10/10 ---\n",
      "\n",
      "Final Answer:\n",
      "Max turns reached. Unable to complete the task.\n"
     ]
    }
   ],
   "source": [
    "answer = agent.run(\"What PDFs are available and what topics do they cover?\")\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-2",
   "metadata": {},
   "source": [
    "### Example 2: Search for Specific Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "example-2-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User Query: What is the lora technique?\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Turn 1/10 ---\n",
      "\n",
      "🔧 Tool Call: find_pdf_files\n",
      "   Arguments: {'directory': './assets-resources/pdfs'}\n",
      "   Result: ./assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf\n",
      "./assets-resources/pdfs/lora-paper.pdf\n",
      "./assets-resources/pdfs/sparks-agi-paper.pdf\n",
      "./assets-resources/pdfs/qlora-paper.pdf\n",
      "\n",
      "--- Turn 2/10 ---\n",
      "\n",
      "🔧 Tool Call: search_pdf\n",
      "   Arguments: {'pdf_path': './assets-resources/pdfs/lora-paper.pdf', 'search_pattern': 'lora technique'}\n",
      "   Result: No matches found for 'lora technique' in ./assets-resources/pdfs/lora-paper.pdf\n",
      "\n",
      "--- Turn 3/10 ---\n",
      "\n",
      "🔧 Tool Call: search_pdf\n",
      "   Arguments: {'pdf_path': './assets-resources/pdfs/lora-paper.pdf', 'search_pattern': 'lora'}\n",
      "   Result: Found matches for 'lora' in ./assets-resources/pdfs/lora-paper.pdf:\n",
      "\n",
      "                                                   we pre-train larger models, full fine-tuning, which retrains all model parameter...\n",
      "\n",
      "--- Turn 4/10 ---\n",
      "\n",
      "✅ Final Answer (after 4 turns):\n",
      "\n",
      "The provided text discusses various adaptation methods for large language models, particularly focusing on LoRA (Low-Rank Adaptation), PrefixEmbed, and PrefixLayer. Here's a summary of the key points:\n",
      "\n",
      "### Adaptation Methods Comparison\n",
      "1. **LoRA (Low-Rank Adaptation)**:\n",
      "   - **Performance**: Generally outperforms or matches fine-tuning and other adaptation methods, especially in low-data scenarios.\n",
      "   - **Sample Efficiency**: Exhibits favorable sample efficiency, performing well even with limited training examples.\n",
      "   - **Hyperparameters**: Typically uses ranks (r) like rq = rv = 8, with variations analyzed for different tasks.\n",
      "\n",
      "2. **PrefixEmbed and PrefixLayer**:\n",
      "   - **Performance**: Generally underperforms compared to LoRA and fine-tuning, especially in low-data tasks.\n",
      "   - **Hyperparameters**: PrefixEmbed uses parameters like lp (prefix length) and li (inner length), while PrefixLayer uses learning rates specific to the method.\n",
      "\n",
      "### Task-Specific Results\n",
      "- **MNLI-n (Multi-Genre Natural Language Inference)**:\n",
      "  - LoRA performs significantly better than PrefixEmbed and PrefixLayer, especially with very few training examples (e.g., MNLI-100).\n",
      "  - Fine-tuning also performs well but is outperformed by LoRA in some cases.\n",
      "\n",
      "- **E2E NLG Challenge**:\n",
      "  - Performance peaks at different ranks (r) for different metrics, suggesting the intrinsic rank for adaptation varies by task and model size.\n",
      "\n",
      "- **DART and WebNLG**:\n",
      "  - LoRA consistently matches or outperforms other adaptation methods, including fine-tuning, across various metrics like BLEU, MET, and TER.\n",
      "\n",
      "### Hyperparameter Analysis\n",
      "- **LoRA**:\n",
      "  - Different ranks (r) are tested, with performance stabilizing or peaking at certain values (e.g., r = 8 for many tasks).\n",
      "  - Combination with PrefixEmbed (LoRA+PE) and PrefixLayer (LoRA+PL) shows varying results, with some combinations improving performance.\n",
      "\n",
      "- **PrefixEmbed and PrefixLayer**:\n",
      "  - Increasing the number of trainable parameters does not necessarily improve performance, unlike LoRA.\n",
      "\n",
      "### Conclusion\n",
      "LoRA is highlighted as a robust and efficient adaptation method, particularly suitable for large language models with limited training data. It often outperforms or matches the performance of fine-tuning and other adaptation methods while being more parameter-efficient. Prefix-based methods, while simpler, tend to underperform in low-data scenarios and are less stable across different tasks.\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "Final Answer:\n",
      "The provided text discusses various adaptation methods for large language models, particularly focusing on LoRA (Low-Rank Adaptation), PrefixEmbed, and PrefixLayer. Here's a summary of the key points:\n",
      "\n",
      "### Adaptation Methods Comparison\n",
      "1. **LoRA (Low-Rank Adaptation)**:\n",
      "   - **Performance**: Generally outperforms or matches fine-tuning and other adaptation methods, especially in low-data scenarios.\n",
      "   - **Sample Efficiency**: Exhibits favorable sample efficiency, performing well even with limited training examples.\n",
      "   - **Hyperparameters**: Typically uses ranks (r) like rq = rv = 8, with variations analyzed for different tasks.\n",
      "\n",
      "2. **PrefixEmbed and PrefixLayer**:\n",
      "   - **Performance**: Generally underperforms compared to LoRA and fine-tuning, especially in low-data tasks.\n",
      "   - **Hyperparameters**: PrefixEmbed uses parameters like lp (prefix length) and li (inner length), while PrefixLayer uses learning rates specific to the method.\n",
      "\n",
      "### Task-Specific Results\n",
      "- **MNLI-n (Multi-Genre Natural Language Inference)**:\n",
      "  - LoRA performs significantly better than PrefixEmbed and PrefixLayer, especially with very few training examples (e.g., MNLI-100).\n",
      "  - Fine-tuning also performs well but is outperformed by LoRA in some cases.\n",
      "\n",
      "- **E2E NLG Challenge**:\n",
      "  - Performance peaks at different ranks (r) for different metrics, suggesting the intrinsic rank for adaptation varies by task and model size.\n",
      "\n",
      "- **DART and WebNLG**:\n",
      "  - LoRA consistently matches or outperforms other adaptation methods, including fine-tuning, across various metrics like BLEU, MET, and TER.\n",
      "\n",
      "### Hyperparameter Analysis\n",
      "- **LoRA**:\n",
      "  - Different ranks (r) are tested, with performance stabilizing or peaking at certain values (e.g., r = 8 for many tasks).\n",
      "  - Combination with PrefixEmbed (LoRA+PE) and PrefixLayer (LoRA+PL) shows varying results, with some combinations improving performance.\n",
      "\n",
      "- **PrefixEmbed and PrefixLayer**:\n",
      "  - Increasing the number of trainable parameters does not necessarily improve performance, unlike LoRA.\n",
      "\n",
      "### Conclusion\n",
      "LoRA is highlighted as a robust and efficient adaptation method, particularly suitable for large language models with limited training data. It often outperforms or matches the performance of fine-tuning and other adaptation methods while being more parameter-efficient. Prefix-based methods, while simpler, tend to underperform in low-data scenarios and are less stable across different tasks.\n"
     ]
    }
   ],
   "source": [
    "answer = agent.run(\"What is the lora technique?\")\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-3",
   "metadata": {},
   "source": [
    "### Example 3: Multi-Step Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-3-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User Query: Summarize in one sentence each of the pdfs.\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Turn 1/10 ---\n",
      "\n",
      "🔧 Tool Call: find_pdf_files\n",
      "   Arguments: {'directory': './assets-resources/pdfs'}\n",
      "   Result: ./assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf\n",
      "./assets-resources/pdfs/lora-paper.pdf\n",
      "./assets-resources/pdfs/sparks-agi-paper.pdf\n",
      "./assets-resources/pdfs/qlora-paper.pdf\n",
      "\n",
      "--- Turn 2/10 ---\n",
      "\n",
      "🔧 Tool Call: search_pdf\n",
      "   Arguments: {'pdf_path': './assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf', 'search_pattern': 'summary'}\n",
      "   Result: Found matches for 'summary' in ./assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf:\n",
      "\n",
      "                                                                        cream.\n",
      "\n",
      "                    ...\n",
      "\n",
      "--- Turn 3/10 ---\n",
      "\n",
      "🔧 Tool Call: search_pdf\n",
      "   Arguments: {'pdf_path': './assets-resources/pdfs/lora-paper.pdf', 'search_pattern': 'summary'}\n",
      "   Result: Found matches for 'summary' in ./assets-resources/pdfs/lora-paper.pdf:\n",
      "\n",
      "reading comprehension (MRC), and natural language to SQL (NL2SQL). Each downstream task is\n",
      "represented by a training dataset of ...\n",
      "\n",
      "--- Turn 4/10 ---\n",
      "\n",
      "✅ Final Answer (after 4 turns):\n",
      "\n",
      "The PDF \"lora-paper.pdf\" discusses the application of LoRA (Low-Rank Adaptation) in various natural language processing tasks, including summarization, and provides details about datasets like SAMSum and E2E NLG Challenge.\n",
      "\n",
      "I will now search for relevant keywords in the next PDF.\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "Final Answer:\n",
      "The PDF \"lora-paper.pdf\" discusses the application of LoRA (Low-Rank Adaptation) in various natural language processing tasks, including summarization, and provides details about datasets like SAMSum and E2E NLG Challenge.\n",
      "\n",
      "I will now search for relevant keywords in the next PDF.\n"
     ]
    }
   ],
   "source": [
    "answer = agent.run(\n",
    "    \"Summarize in one sentence each of the pdfs.\"\n",
    ")\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding",
   "metadata": {},
   "source": [
    "## Understanding the ReAct Loop\n",
    "\n",
    "Let's break down what happens in each turn:\n",
    "\n",
    "1. **Turn 1**: Agent receives user query, decides to call `find_pdfs` to discover available documents\n",
    "2. **Turn 2**: Agent receives list of PDFs, decides to call `search_pdf` with a relevant keyword\n",
    "3. **Turn 3**: Agent receives search results, may search more PDFs or read specific pages\n",
    "4. **Turn N**: Agent has enough information, provides final answer\n",
    "\n",
    "The agent autonomously decides:\n",
    "- Which tools to use\n",
    "- What arguments to pass\n",
    "- When it has enough information to answer\n",
    "\n",
    "This is the power of agentic systems!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "customization",
   "metadata": {},
   "source": [
    "## Customization Tips\n",
    "\n",
    "You can easily extend this agent by:\n",
    "\n",
    "1. **Adding more tools**: Create new functions and add them to `TOOLS` and `tools_map`\n",
    "2. **Changing the model**: Use different Ollama models like `qwen3`, etc.\n",
    "3. **Adjusting max_turns**: Control how many reasoning steps the agent can take\n",
    "4. **Modifying the system prompt**: Change the agent's behavior and personality\n",
    "5. **Adding memory**: Store conversation history across multiple runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",
   "metadata": {},
   "source": [
    "## Comparison: Simple Agent vs Framework\n",
    "\n",
    "**Our Simple Agent (~100 lines):**\n",
    "- ✅ Full control over every step\n",
    "- ✅ Easy to understand and debug\n",
    "- ✅ No external dependencies (just Ollama)\n",
    "- ✅ Perfect for learning and teaching\n",
    "- ❌ Limited features\n",
    "- ❌ Manual tool integration\n",
    "\n",
    "**Framework (e.g., SmoLAgents, LangChain):**\n",
    "- ✅ Many built-in tools and features\n",
    "- ✅ Production-ready\n",
    "- ✅ Advanced capabilities (memory, planning, etc.)\n",
    "- ❌ Steeper learning curve\n",
    "- ❌ Abstractions can hide important details\n",
    "- ❌ Additional dependencies\n",
    "\n",
    "**When to use each:**\n",
    "- Use simple agent: Learning, prototyping, simple tasks, full control\n",
    "- Use framework: Production systems, complex workflows, team projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Try these challenges to deepen your understanding:\n",
    "\n",
    "1. **Add a new tool** that can extract metadata from PDFs (author, title, creation date)\n",
    "2. **Modify the system prompt** to make the agent more concise or more detailed\n",
    "3. **Add conversation memory** so the agent remembers previous queries\n",
    "4. **Create a comparison tool** that can search multiple PDFs and compare results\n",
    "5. **Add error handling** to gracefully handle missing PDFs or invalid queries\n",
    "6. **Implement streaming** to show the agent's reasoning in real-time\n",
    "7. **Add a summarization tool** that can summarize entire PDFs or sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You've built a simple but powerful agentic RAG system from scratch! Key takeaways:\n",
    "\n",
    "1. **ReAct Loop**: The pattern of Reason → Act → Observe is fundamental to agents\n",
    "2. **Tool Calling**: LLMs can decide which tools to use and when\n",
    "3. **Local Models**: Ollama makes it easy to run agents completely locally\n",
    "4. **Simplicity**: You don't need complex frameworks to build useful agents\n",
    "\n",
    "This foundational understanding will help you work with any agent framework and build more sophisticated systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
